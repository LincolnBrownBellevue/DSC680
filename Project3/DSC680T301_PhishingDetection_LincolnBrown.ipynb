{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "98771071-4a66-4cff-b79b-bd9115f0106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "99161a60-6106-4e38-8d95-08d3042a570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = './Phishing_Email.csv'\n",
    "df = pd.read_csv(f, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1dfdd451-5bd9-4c5e-8c5f-0c0398239d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email Text</th>\n",
       "      <th>Email Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>re : 6 . 1100 , disc : uniformitarianism , re ...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the other side of * galicismos * * galicismo *...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>re : equistar deal tickets are you still avail...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nHello I am your hot lil horny toy.\\n    I am...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>software at incredibly low prices ( 86 % lower...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18646</th>\n",
       "      <td>date a lonely housewife always wanted to date ...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18647</th>\n",
       "      <td>request submitted : access request for anita ....</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18648</th>\n",
       "      <td>re : important - prc mtg hi dorn &amp; john , as y...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18649</th>\n",
       "      <td>press clippings - letter on californian utilit...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18650</th>\n",
       "      <td>empty</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18650 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Email Text      Email Type\n",
       "0      re : 6 . 1100 , disc : uniformitarianism , re ...      Safe Email\n",
       "1      the other side of * galicismos * * galicismo *...      Safe Email\n",
       "2      re : equistar deal tickets are you still avail...      Safe Email\n",
       "3      \\nHello I am your hot lil horny toy.\\n    I am...  Phishing Email\n",
       "4      software at incredibly low prices ( 86 % lower...  Phishing Email\n",
       "...                                                  ...             ...\n",
       "18646  date a lonely housewife always wanted to date ...  Phishing Email\n",
       "18647  request submitted : access request for anita ....      Safe Email\n",
       "18648  re : important - prc mtg hi dorn & john , as y...      Safe Email\n",
       "18649  press clippings - letter on californian utilit...      Safe Email\n",
       "18650                                              empty  Phishing Email\n",
       "\n",
       "[18650 rows x 2 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b59cb-76ba-4d7e-94ae-48c3eb50eb2d",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "da559678-4bb3-4423-9235-2680f351e6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Email Text    16\n",
       "Email Type     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of null values in the dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "dd2ca56f-3438-44fe-a9c6-d5a674f3974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the na's\n",
    "clean_df = df.copy()\n",
    "clean_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "63959e57-d851-4623-bc9d-cad2e4eaf279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for records that contain the text 'empty'\n",
    "# These records will also be considered missing and dropped as well\n",
    "\n",
    "len(clean_df.loc[clean_df['Email Text'] == 'empty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7f43f4ac-053a-44df-885e-355fa5aa7c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select records that do not have the email text 'empty'\n",
    "clean_df = clean_df[clean_df['Email Text'] != 'empty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ae855c37-bc82-4a24-abde-12a691900039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18101, 2)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the shape after removing nulls\n",
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "de9cf97d-f484-4e12-acac-4eab7141a4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/x/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/x/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download stopwords from nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60684741-3306-4704-8c61-2e34319316ce",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3394cc78-a589-436f-9b42-1fbeb38aca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Encode the Email Type\n",
    "clean_df.loc[:, 'Email Type'] =  clean_df['Email Type'].map({'Phishing Email': 1, 'Safe Email': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f4260af8-d36f-41b4-867d-d43a8458ddfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to int64\n",
    "clean_df['Email Type'] = pd.to_numeric(clean_df['Email Type'])\n",
    "clean_df['Email Type'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "bd91db4d-ebeb-48b9-bc04-f92246abfc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the function to clean the text\n",
    "\n",
    "def bow_preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text) # Remove special characters\n",
    "    text = re.sub(r'\\d+', ' ', text) # Remove numbers\n",
    "    text = re.sub(r'\\s_', ' ', text).strip() # Remove extra spaces\n",
    "    text = text.lower()\n",
    "    words = word_tokenize(text) # Tokenization\n",
    "    words = [word for word in words if word not in stopwords.words('english')] # Remove stop words\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "dd67b401-d808-4511-ae29-fbde35ad5b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text\n",
    "clean_df['Cleaned Text'] = clean_df['Email Text'].apply(bow_preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "64df773a-722e-4ca3-a29e-d2f2a4c7da6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email Text</th>\n",
       "      <th>Email Type</th>\n",
       "      <th>Cleaned Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>re : 6 . 1100 , disc : uniformitarianism , re ...</td>\n",
       "      <td>0</td>\n",
       "      <td>disc uniformitarianism sex lang dick hudson ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the other side of * galicismos * * galicismo *...</td>\n",
       "      <td>0</td>\n",
       "      <td>side galicismos galicismo spanish term names i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>re : equistar deal tickets are you still avail...</td>\n",
       "      <td>0</td>\n",
       "      <td>equistar deal tickets still available assist r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nHello I am your hot lil horny toy.\\n    I am...</td>\n",
       "      <td>1</td>\n",
       "      <td>hello hot lil horny toy one dream open minded ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>software at incredibly low prices ( 86 % lower...</td>\n",
       "      <td>1</td>\n",
       "      <td>software incredibly low prices lower drapery s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18645</th>\n",
       "      <td>\\nRick Moen  a ÃƒÂ©crit:&gt; &gt; I'm confused. I thou...</td>\n",
       "      <td>0</td>\n",
       "      <td>rick moen Ã£ crit confused thought gpl ed money...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18646</th>\n",
       "      <td>date a lonely housewife always wanted to date ...</td>\n",
       "      <td>1</td>\n",
       "      <td>date lonely housewife always wanted date lonel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18647</th>\n",
       "      <td>request submitted : access request for anita ....</td>\n",
       "      <td>0</td>\n",
       "      <td>request submitted access request anita dupont ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18648</th>\n",
       "      <td>re : important - prc mtg hi dorn &amp; john , as y...</td>\n",
       "      <td>0</td>\n",
       "      <td>important prc mtg hi dorn john discovered rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18649</th>\n",
       "      <td>press clippings - letter on californian utilit...</td>\n",
       "      <td>0</td>\n",
       "      <td>press clippings letter californian utilities p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18101 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Email Text  Email Type  \\\n",
       "0      re : 6 . 1100 , disc : uniformitarianism , re ...           0   \n",
       "1      the other side of * galicismos * * galicismo *...           0   \n",
       "2      re : equistar deal tickets are you still avail...           0   \n",
       "3      \\nHello I am your hot lil horny toy.\\n    I am...           1   \n",
       "4      software at incredibly low prices ( 86 % lower...           1   \n",
       "...                                                  ...         ...   \n",
       "18645  \\nRick Moen  a ÃƒÂ©crit:> > I'm confused. I thou...           0   \n",
       "18646  date a lonely housewife always wanted to date ...           1   \n",
       "18647  request submitted : access request for anita ....           0   \n",
       "18648  re : important - prc mtg hi dorn & john , as y...           0   \n",
       "18649  press clippings - letter on californian utilit...           0   \n",
       "\n",
       "                                            Cleaned Text  \n",
       "0      disc uniformitarianism sex lang dick hudson ob...  \n",
       "1      side galicismos galicismo spanish term names i...  \n",
       "2      equistar deal tickets still available assist r...  \n",
       "3      hello hot lil horny toy one dream open minded ...  \n",
       "4      software incredibly low prices lower drapery s...  \n",
       "...                                                  ...  \n",
       "18645  rick moen Ã£ crit confused thought gpl ed money...  \n",
       "18646  date lonely housewife always wanted date lonel...  \n",
       "18647  request submitted access request anita dupont ...  \n",
       "18648  important prc mtg hi dorn john discovered rece...  \n",
       "18649  press clippings letter californian utilities p...  \n",
       "\n",
       "[18101 rows x 3 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9ba9b9cc-7bed-45f6-a05f-a037cda4f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(clean_df['Cleaned Text'], clean_df['Email Type'], test_size=0.2, random_state=42, stratify=clean_df['Email Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e516dd2d-9f52-49c6-b27b-27a55ef01e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd81292b-19d8-47e2-bc0e-5d9b93c35e0e",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "18a4a675-3df1-4243-83ff-92675d3bd6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9762\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2225\n",
      "           1       0.97      0.96      0.97      1396\n",
      "\n",
      "    accuracy                           0.98      3621\n",
      "   macro avg       0.98      0.97      0.97      3621\n",
      "weighted avg       0.98      0.98      0.98      3621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "# Create the LR model\n",
    "lr_model = LogisticRegression()\n",
    "# Train the LR Model\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evalute model performance\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Classification Report: \\n{classification_report(y_test, y_pred_lr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9cbad3b2-f0f8-4cd3-971e-6d04aecc7f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['remove', 'sightings', 'click', 'money', 'free', 'email', 'removed', 'save', 'site', 'reply', 'software', 'offer', 'hello', 'life', 'rolex', 'best', 'viagra', 'quality', 'mobile', 'meds']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "top_coefs = lr_model.coef_[0].argsort()[::-1][:20]\n",
    "print([feature_names[i] for i in top_coefs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f911e368-074f-4f0f-b2e0-a1656f077147",
   "metadata": {},
   "source": [
    "## BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0b2226f7-7624-4666-8fa0-691d68859c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67ca014b0e14a19937eeb054f539a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde1e5da56a84ba28239b3473e199659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe98aa91c864a2b9c134f71d7ba1292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04cc5ed18d994d45912a958577de50b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "42b62c0d-4b36-4b58-b52d-4f5901d3821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(texts):\n",
    "    return tokenizer(texts.tolist(), padding=True, truncation=True, max_length=512, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "be6d32e0-590a-4d98-934b-a7a31b84dfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenize_function(X_train)\n",
    "test_encodings = tokenize_function(X_test)\n",
    "\n",
    "train_labels = torch.tensor(y_train.tolist())\n",
    "test_labels = torch.tensor(y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "34cdf1d5-76d2-4014-8945-ed46cabf7e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Create the Bert Model\n",
    "bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "368ec8dd-c22a-4e5f-b52c-8c699a6a3dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8757f243-f09c-4a5a-82a6-6687bafbc124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "bert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6dec967c-3f8a-4ff7-a8cd-8933f619a4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 218.3467\n",
      "Epoch 2, Loss: 110.8521\n",
      "Epoch 3, Loss: 37.7403\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(bert_model.parameters(), lr=5e-5)\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    bert_model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = bert_model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "727b963b-7dfe-4a0a-95f8-17a5ad78ae77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2225\n",
      "           1       0.98      0.99      0.98      1396\n",
      "\n",
      "    accuracy                           0.99      3621\n",
      "   macro avg       0.98      0.99      0.99      3621\n",
      "weighted avg       0.99      0.99      0.99      3621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_model.eval()\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "\n",
    "        outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "        predictions.extend(preds)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy_score(true_labels, predictions):.4f}')\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a3ad1-a94f-4128-90bd-08c09ca851b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
